{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "# Named Entity Recognition With Parallel Recurrent Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": "This paper is for using parallel RNN to predict the tag of entities. By using Parallel RNN, we can reduce the number of parameter of the network thus make the training time faster.  In order to use the library, the users need to download embeddings of [GloVe](https://nlp.stanford.edu/projects/glove/) that translates words into float vectors. The embedding file should be put under `./data/embeddings/` folder. In this demostration, we use `glove.6B.100d.txt` which is **100** dimensions."
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "Besides of embedding file, we also need training dataset to train the CNN model. In this document, we use [CoNLL 2003](https://www.clips.uantwerpen.be/conll2003/ner/) as the dataset. It could be download from many places, e.g., from [here](https://github.com/synalp/NER/tree/master/corpus/CoNLL-2003). There will be 3 files in the dataset, i.e. `train.txt` for training, `valid.txt` for validating the model during the training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": "After all preparations are done, we need to confirm the Python is version 3 and TensorFlow is 1.13.1."
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.13.1\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf; print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## Import the library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "The first step to use the library is to `import` it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ],
      "source": "import extraction.named_entity.yiran.paper2.Ner as Ner"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": "uoi \u003d Ner.UOI()"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## Read the data set for training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "There are two parameters in the `read_dataset` method, which are `input_files` containing two pathes for train dataset, valid dataset and `embedding` for embedding file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": "train_sen, train_tag, val_sen, val_tag \u003d uoi.read_dataset(input_files\u003d[\u0027/home/ubuntu/UOI-P18-2012/dataset/CoNNL2003eng/train.txt\u0027,\n                                                                                    \u0027/home/ubuntu/UOI-P18-2012/dataset/CoNNL2003eng/valid.txt\u0027],\n                                                                       embedding\u003d\u0027/home/ubuntu/UOI-P18-2012/dataset/CoNNL2003eng/glove.6B.100d.txt\u0027)"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "The return value contains `train_sen`, an array containing all training sentences, `train_tag`, an array containing all tags for the training sentences, `val_sen`, an array containing validating sentences, `val_tag`, an array of validating tags."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[\u0027EU\u0027, \u0027rejects\u0027, \u0027German\u0027, \u0027call\u0027, \u0027to\u0027, \u0027boycott\u0027, \u0027British\u0027, \u0027lamb\u0027, \u0027.\u0027],\n",
              " [\u0027Peter\u0027, \u0027Blackburn\u0027],\n",
              " [\u0027BRUSSELS\u0027, \u00271996-08-22\u0027]]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_sen[0:3] #let\u0027s see an sample "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": "After reading the dataset, we can start to train the model. **In order to speed up the process, only one epoch will be trained and the F1 score might be very low**. There will be a file added `model.h5` will be created so **please confirm python have the privilege to create a file.**"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding...\n",
            "Embedding open file\n",
            "Embedding for loop\n",
            "Embedding done\n",
            "Embedding all done\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\n",
            "Input_Char (InputLayer)         (None, None, 61)     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Input_Word (InputLayer)         (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Embedding_Char_Pre (Embedding)  (None, None, 61, 100 8600        Input_Char[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "Embedding_Word (Embedding)      (None, None, 100)    40000200    Input_Word[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "Embedding_Char (TimeDistributed (None, None, 100)    60400       Embedding_Char_Pre[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Embedding (Concatenate)         (None, None, 200)    0           Embedding_Word[0][0]             \n",
            "                                                                 Embedding_Char[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "LSTM_1 (Bidirectional)          (None, None, 64)     59648       Embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "LSTM_2 (Bidirectional)          (None, None, 64)     59648       Embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "LSTM_3 (Bidirectional)          (None, None, 64)     59648       Embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "LSTM_4 (Bidirectional)          (None, None, 64)     59648       Embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "LSTM_5 (Bidirectional)          (None, None, 64)     59648       Embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "LSTM_6 (Bidirectional)          (None, None, 64)     59648       Embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "LSTM_7 (Bidirectional)          (None, None, 64)     59648       Embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "LSTM_8 (Bidirectional)          (None, None, 64)     59648       Embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "LSTM_9 (Bidirectional)          (None, None, 64)     59648       Embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "LSTM_10 (Bidirectional)         (None, None, 64)     59648       Embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "LSTM_11 (Bidirectional)         (None, None, 64)     59648       Embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "LSTM_12 (Bidirectional)         (None, None, 64)     59648       Embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "LSTM_13 (Bidirectional)         (None, None, 64)     59648       Embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "LSTM_14 (Bidirectional)         (None, None, 64)     59648       Embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "LSTM_15 (Bidirectional)         (None, None, 64)     59648       Embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "LSTM_16 (Bidirectional)         (None, None, 64)     59648       Embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "Concatenation (Concatenate)     (None, None, 1024)   0           LSTM_1[0][0]                     \n",
            "                                                                 LSTM_2[0][0]                     \n",
            "                                                                 LSTM_3[0][0]                     \n",
            "                                                                 LSTM_4[0][0]                     \n",
            "                                                                 LSTM_5[0][0]                     \n",
            "                                                                 LSTM_6[0][0]                     \n",
            "                                                                 LSTM_7[0][0]                     \n",
            "                                                                 LSTM_8[0][0]                     \n",
            "                                                                 LSTM_9[0][0]                     \n",
            "                                                                 LSTM_10[0][0]                    \n",
            "                                                                 LSTM_11[0][0]                    \n",
            "                                                                 LSTM_12[0][0]                    \n",
            "                                                                 LSTM_13[0][0]                    \n",
            "                                                                 LSTM_14[0][0]                    \n",
            "                                                                 LSTM_15[0][0]                    \n",
            "                                                                 LSTM_16[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "Dense (Dense)                   (None, None, 9)      9225        Concatenation[0][0]              \n",
            "\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\n",
            "Total params: 41,032,793\n",
            "Trainable params: 1,032,593\n",
            "Non-trainable params: 40,000,200\n",
            "__________________________________________________________________________________________________\n",
            "loading model from:  model.h5\n"
          ]
        }
      ],
      "source": [
        "uoi.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## Predict the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "After having model trained, we can try to predict new sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "predict_file\u003d\u0027dataset/CoNNL2003eng/test.txt\u0027\n",
        "tokens, tags, predicts \u003d uoi.predict(predict_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "There will 3 return values from this method. The first one is the tokens, the second one is ground truth tags and last one is the predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[\u0027SOCCER\u0027, \u0027-\u0027, \u0027JAPAN\u0027, \u0027GET\u0027, \u0027LUCKY\u0027, \u0027WIN\u0027, \u0027,\u0027, \u0027CHINA\u0027, \u0027IN\u0027, \u0027SURPRISE\u0027, \u0027DEFEAT\u0027, \u0027.\u0027], [\u0027Nadim\u0027, \u0027Ladki\u0027], [\u0027AL-AIN\u0027, \u0027,\u0027, \u0027United\u0027, \u0027Arab\u0027, \u0027Emirates\u0027, \u00271996-12-06\u0027], [\u0027Japan\u0027, \u0027began\u0027, \u0027the\u0027, \u0027defence\u0027, \u0027of\u0027, \u0027their\u0027, \u0027Asian\u0027, \u0027Cup\u0027, \u0027title\u0027, \u0027with\u0027, \u0027a\u0027, \u0027lucky\u0027, \u00272-1\u0027, \u0027win\u0027, \u0027against\u0027, \u0027Syria\u0027, \u0027in\u0027, \u0027a\u0027, \u0027Group\u0027, \u0027C\u0027, \u0027championship\u0027, \u0027match\u0027, \u0027on\u0027, \u0027Friday\u0027, \u0027.\u0027], [\u0027But\u0027, \u0027China\u0027, \u0027saw\u0027, \u0027their\u0027, \u0027luck\u0027, \u0027desert\u0027, \u0027them\u0027, \u0027in\u0027, \u0027the\u0027, \u0027second\u0027, \u0027match\u0027, \u0027of\u0027, \u0027the\u0027, \u0027group\u0027, \u0027,\u0027, \u0027crashing\u0027, \u0027to\u0027, \u0027a\u0027, \u0027surprise\u0027, \u00272-0\u0027, \u0027defeat\u0027, \u0027to\u0027, \u0027newcomers\u0027, \u0027Uzbekistan\u0027, \u0027.\u0027]]\n"
          ]
        }
      ],
      "source": [
        "print(tokens[0:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[\u0027O\u0027, \u0027O\u0027, \u0027B-LOC\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027B-LOC\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027], [\u0027B-PER\u0027, \u0027I-ORG\u0027], [\u0027B-LOC\u0027, \u0027O\u0027, \u0027B-LOC\u0027, \u0027I-MISC\u0027, \u0027I-LOC\u0027, \u0027O\u0027], [\u0027B-LOC\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027B-MISC\u0027, \u0027I-MISC\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027B-LOC\u0027, \u0027O\u0027, \u0027O\u0027, \u0027I-ORG\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027], [\u0027O\u0027, \u0027B-LOC\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027B-LOC\u0027, \u0027O\u0027]]\n"
          ]
        }
      ],
      "source": [
        "print(tags[0:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[\u0027O\u0027, \u0027O\u0027, \u0027B-LOC\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027B-PER\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027], [\u0027B-PER\u0027, \u0027I-PER\u0027], [\u0027B-LOC\u0027, \u0027O\u0027, \u0027B-LOC\u0027, \u0027I-LOC\u0027, \u0027I-LOC\u0027, \u0027O\u0027], [\u0027B-LOC\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027B-MISC\u0027, \u0027I-MISC\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027B-LOC\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027], [\u0027O\u0027, \u0027B-LOC\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027B-LOC\u0027, \u0027O\u0027]]\n"
          ]
        }
      ],
      "source": [
        "print(predicts[0:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "The `evaluation` method is for checking the performance of the model. The arguments for this method are not used since the statistics are generated during the prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.87972996982062, 0.8767705382654443, 0.8782477609509182)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "uoi.evaluate([],[])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "The `convert_ground_truth` method takes one parameter of the path of test file. The return value is the list of tags."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "result \u003d uoi.convert_ground_truth(\u0027dataset/CoNNL2003eng/test.txt\u0027)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[\u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027B-LOC\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027O\u0027, \u0027B-PER\u0027, \u0027O\u0027]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result[0:10]"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}